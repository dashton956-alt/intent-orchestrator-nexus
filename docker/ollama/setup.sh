
#!/bin/bash

echo "ğŸš€ Setting up Ollama Docker container..."

# Build and start the container
docker-compose up -d

echo "â³ Waiting for Ollama to start..."
sleep 30

# Pull the required model
echo "ğŸ“¥ Pulling llama3.1 model..."
docker exec ollama-ai ollama pull llama3.1

echo "ğŸ“¥ Pulling additional recommended models..."
docker exec ollama-ai ollama pull mistral
docker exec ollama-ai ollama pull codellama

# Test the setup
echo "ğŸ§ª Testing Ollama API..."
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.1",
    "prompt": "Hello, are you working?",
    "stream": false
  }'

echo ""
echo "âœ… Ollama setup complete!"
echo "ğŸŒ Ollama is running at: http://localhost:11434"
echo "ğŸ“Š API health check: http://localhost:11434/api/tags"
